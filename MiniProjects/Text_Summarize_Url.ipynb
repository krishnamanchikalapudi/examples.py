{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a369ad-3b4c-4192-804b-f598ce0065b6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce1cad-96c6-4ec8-9654-f2674dbe5ecb",
   "metadata": {},
   "source": [
    "Read website content and summarize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb051742-497d-41a2-9ec1-084998b0e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# BEGIN: fix Python or Notebook SSL CERTIFICATE_VERIFY_FAILED\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# END: fix Python or Notebook SSL CERTIFICATE_VERIFY_FAILED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d2ffc-6060-40ce-81b9-243b084e2e70",
   "metadata": {},
   "source": [
    "## Installing pre-requsite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be140368-168b-4f98-868b-6bc97752ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (21.1.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc5512b-5d84-40d4-85c5-67c4bdb305bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (4.9.3)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (4.61.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ornado (/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U beautifulsoup4 nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7dcc44-b348-4162-b8d9-2bbfbe85b1bc",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3731d6d-27f5-4f61-991a-3cb631068237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/krishnamanchikalapudi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/krishnamanchikalapudi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import urllib as url\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "import re, string, unicodedata\n",
    "from heapq import nlargest\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5ba7a-be6a-46ad-b009-2ae5eb0b75a5",
   "metadata": {},
   "source": [
    "### Read public url content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4c2d90-58b6-4678-bcc6-757888a2acf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-827d3aaa62fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://timesofindia.indiatimes.com/life-style/health-fitness/diet/do-you-know-why-garlic-and-onion-are-not-recommended-in-ayurveda/articleshow/70619176.cms\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# article\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "content = \"https://timesofindia.indiatimes.com/life-style/health-fitness/diet/do-you-know-why-garlic-and-onion-are-not-recommended-in-ayurveda/articleshow/70619176.cms\"\n",
    "article = url.request.urlopen(content)\n",
    "article = article.read()\n",
    "\n",
    "# article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515de5db-bd9a-44bd-bb9a-0e41aca5fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_table(text_string) -> dict:\n",
    "    \"\"\"\n",
    "    we create a dictionary for the word frequency table.\n",
    "    For this, we should only use the words that are not part of the stopWords array.\n",
    "    Removing stop words and making frequency table\n",
    "    Stemmer - an algorithm to bring words to its root word.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text_string)\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else:\n",
    "            freqTable[word] = 1\n",
    "\n",
    "    return freqTable\n",
    "\n",
    "\n",
    "def _score_sentences(sentences, freqTable) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its words\n",
    "    Basic algorithm: adding the frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        word_count_in_sentence = (len(word_tokenize(sentence)))\n",
    "        word_count_in_sentence_except_stop_words = 0\n",
    "        for wordValue in freqTable:\n",
    "            if wordValue in sentence.lower():\n",
    "                word_count_in_sentence_except_stop_words += 1\n",
    "                if sentence[:10] in sentenceValue:\n",
    "                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n",
    "                else:\n",
    "                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n",
    "\n",
    "        if sentence[:10] in sentenceValue:\n",
    "            sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] / word_count_in_sentence_except_stop_words\n",
    "\n",
    "        '''\n",
    "        Notice that a potential issue with our score algorithm is that long sentences will have an advantage over short sentences. \n",
    "        To solve this, we're dividing every sentence score by the number of words in the sentence.\n",
    "        \n",
    "        Note that here sentence[:10] is the first 10 character of any sentence, this is to save memory while saving keys of\n",
    "        the dictionary.\n",
    "        '''\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "\n",
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "\n",
    "\n",
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51e06a-e9f7-469e-b2b2-75a84ba40913",
   "metadata": {},
   "source": [
    "## Parsing the article\n",
    "* Beautiful Soup documentation at https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b6134-dca4-49e1-9f76-d07d42b69f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_article = bs.BeautifulSoup(article, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f6f856-cb1e-43b8-899b-298903820232",
   "metadata": {},
   "source": [
    "### Extract Pragraphs from the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c4cc0-01fb-49aa-8ed9-f42bd7b2da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = parse_article.find_all('p')\n",
    "article_text = ''\n",
    "for p in paragraphs:\n",
    "    article_text += p.text \n",
    "# article_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5edb05-c269-4423-9ef6-ae654549b533",
   "metadata": {},
   "source": [
    "## Tokenize the article content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34621f-1185-49c3-af38-44a83327c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(article_text)\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585d836-0b5b-418a-89ba-49caa6d4019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "punctuation = string.punctuation + '\\n'\n",
    "# punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3cf65f-2796-4ebd-80c6-c48ac2c0a607",
   "metadata": {},
   "source": [
    "### Find frequent words in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc41998-e34d-4feb-8943-7d849a9e39a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = {}\n",
    "for word in tokens:    \n",
    "    if word.lower() not in stop_words:\n",
    "        if word.lower() not in punctuation:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "# word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1b588-89e2-4bc7-9346-da1f3953db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frequency = 1\n",
    "\n",
    "if (len(word_frequencies) > 0):\n",
    "    max_frequency = max(word_frequencies.values())\n",
    "\n",
    "print(max_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6223e-175f-41c3-ba15-70f5ba80ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency\n",
    "\n",
    "# print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770dd418-63f6-4c8f-9ee9-a3fb9fe70154",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = sent_tokenize(article_text)\n",
    "# sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c4759-7181-48bc-ae4f-a05cfc13688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sent_token:\n",
    "    sentence = sent.split(\" \")\n",
    "    for word in sentence:        \n",
    "        if word.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.lower()]\n",
    "\n",
    "# sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cf63e-99d3-4a3d-a2ba-84b218a3be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_length = int(len(sent_token)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf151ce-f008-4c01-9e9e-875efad71026",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "\n",
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a7701-9a6a-4ae5-96fd-26f381660383",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = [word for word in summary]\n",
    "\n",
    "summary = ' '.join(final_summary)\n",
    "\n",
    "# print(f\"Original article words: {len(article_text)}, Summary words: {len(summary)}\\n\\n\")\n",
    "# summary = summary.replace('\\u200c', '')\n",
    "str_en = summary.encode(\"ascii\", \"ignore\")\n",
    "summary = str_en.decode()\n",
    "\n",
    "# remove urls\n",
    "# summary = re.sub(r\"http\\S+\", \"\", summary)\n",
    "summary = summary.replace('http', ' http')\n",
    "# summary = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340c81f-6d20-417d-b948-bcede5af1753",
   "metadata": {},
   "source": [
    "## Original content Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c1937-c6c3-4be6-97e2-db33d84e8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1dd8a-2575-4b80-9fab-0ef75e914edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Create the word frequency table\n",
    "freq_table = _create_frequency_table(summary)\n",
    "\n",
    "# We already have a sentence tokenizer, so we just need  to run the sent_tokenize() method to create the array of sentences.\n",
    "\n",
    "# 2 Tokenize the sentences\n",
    "sentences = sent_tokenize(summary)\n",
    "\n",
    "# 3 Important Algorithm: score the sentences\n",
    "sentence_scores = _score_sentences(sentences, freq_table)\n",
    "\n",
    "# 4 Find the threshold\n",
    "threshold = _find_average_score(sentence_scores)\n",
    "\n",
    "# 5 Important Algorithm: Generate the summary\n",
    "summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
    "\n",
    "print(f\"Original article words: {len(article_text)}, Summary words: {len(summary)}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6870c5bb-03f3-4268-b2dc-7f4351e2c743",
   "metadata": {},
   "source": [
    "## Summary of Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a1a66-1c03-4ec5-8483-bd2ccb45eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(summary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
